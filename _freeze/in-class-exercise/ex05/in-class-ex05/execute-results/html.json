{
  "hash": "c3340df3d65a113e0606ca0c1b4ed8e4",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"05 In-class Exercise (Review)\"\nauthor: \"Heng Kuan Xin\"\ndate: 2024-09-16\ndate-modified: \"last-modified\"\n\ntoc: true\ntoc-expand: true\nnumber-sections: true\n\nexecute:\n  eval: true\n  echo: true\n  freeze: true\n  output: true\n  warning: false\n  error: false\n---\n\n\n\n# Recap:\n\nGeographically referenced attributes\n\n-\\> entities are geographically referenced/have a location -\\> either polygons or points.\n\nPreliminary Visualisation -\\> Just map it out on a map, then obtain\n\n## Spatial Weights\n\nTypes of Relationships to define Spatial Weights:\n\n-   Adjacent relationships (common boundary), also called Adjacency.\n    -   if polygon data, there are also concerns that if a polygon is very long, then they will have a high adjacency count.\n-   Distance based relationships;\n    -   if **polygon data**, the algorithm will find the centroids of each polygon. However, limitation: large and irregularly shaped polygons will result in centroids being extremely far away from others. To 'fix' this, we can shift the centroids of these large polygons closer to the other neighbours (depends on context.)\n    -   if **multipolygon/multipoint data**, then you should choose the only necessary points so that your centroids or points are not in the middle of nowhere.\n    -   If points, it will be easier --\\> just distance between points.\n\n### When defining Spatial Weights\n\n-   we can use binary metrics (whether within a search radius/distance)\n-   a continuous metrics (higher weights if near, lower weights if further)\n\n### Adjacency methods of Choosing Neighbours\n\n-   See: Rooks Case, Bishops Case, Queens/Kings Case\n-   Lagged Adjacency for continuity metric, see first order adjacency, second order adjacency, i.e. (neighbour of neighbour)\n\n### Standardising Weights\n\n-   In practice, we will not use spatial weights as-is, we will standardise the weights by row or by columns (gives the same final results as the matrix is symmetrical).\n-   The summation of standardised weights will therefore be an average average.\n\n\\*GDPPC –\\> GDP per capita\n\n# In-class Exercise 05\n\nFocus: Geographically Weighted Summary Statitstics with adaptive Bandwidth\n\n## Importing the necessary\n\nWe will be using a different version called [GWmodel](https://cran.r-project.org/web/packages/GWmodel/index.html); Geographically-Weighted Models The latest date as of writing, is 2.4-1.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(sf,spdep, tmap, tidyverse, knitr, GWmodel)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan_sf <- st_read(dsn=\"data/geospatial\", layer=\"Hunan\")\nhunan_2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")\n```\n:::\n\n\n\nIf we have a dataset where we do not exactly know the projection CRS, there is no choice but to use non-projected CRS. But in this case, we should search for the EPSG Code for projected CRS at Hunan, China\n\n### Join and Filter Out Unwanted Attributes\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan <- left_join(hunan_sf, hunan_2012, by=\"County\") %>%\n  select(1:3,7,15,16,31,32) # Selecting NAME_2, ID_3, NAME_3, County, GDPPC, GIO, Agri, Service\n```\n:::\n\n\n\n### Exporting our data\n\nOnce done, we will export our cleaned data set as a RDS file, so that we only to load in our final\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(hunan,\"data/rds/hunan_sf.rds\")\n```\n:::\n\n\n\n### Reading back our data\n\n\n\n::: {.cell}\n\n:::\n\n\n\n### Converting to SpatialPolygonDataFrame\n\nNote: if we try to run GWmodel, we realise that GWmodel is built around the older sp and not sf formats for handling spatial data in R.\n\nIn sp, we have multiple lists –\\> **data polygons** **proj4string**\n\nLooking through, we are able to see that the attributes are\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan_sp <- hunan_sf %>% as_Spatial()\n```\n:::\n\n\n\n### Determine adaptive bandwidth.\n\nNote that .gwr is used for regression, but we just want to use their model. Without providing an actual function, we write GDPPC \\~ 1 –\\> which means GDPPC is a function of 1, i.e. GDPPC = GDPPC.\n\n::: callout-caution\nOur data is in lat,long, when we pass it through the algorithm, the algorithm will use the Great Circle projection. **The output will be in kilometers (rather than metres)!**\n:::\n\nGDPPC \\~ 1\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbw_AIC <- bw.gwr(GDPPC ~ 1,\n                 data= hunan_sp,\n                 approach = \"AIC\",    # or use CV (Cross-Validation) the AI models\n                 adaptive = TRUE,     # calculate \n                 kernel = \"bisquare\", #\n                 longlat = TRUE)      # Given that our data is in latlong, the great circle  \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAdaptive bandwidth (number of nearest neighbours): 62 AICc value: 1923.156 \nAdaptive bandwidth (number of nearest neighbours): 46 AICc value: 1920.469 \nAdaptive bandwidth (number of nearest neighbours): 36 AICc value: 1917.324 \nAdaptive bandwidth (number of nearest neighbours): 29 AICc value: 1916.661 \nAdaptive bandwidth (number of nearest neighbours): 26 AICc value: 1914.897 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \n```\n\n\n:::\n:::\n\n\n\nNote that we can see 22 Nearest Neighbours\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbw_CV <- bw.gwr(GDPPC ~ 1,\n                 data= hunan_sp,\n                 approach = \"CV\",\n                 adaptive = TRUE,     # calculate \n                 kernel = \"bisquare\", #\n                 longlat = TRUE)      # Given that our data is in latlong, the great circle  \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAdaptive bandwidth: 62 CV score: 15515442343 \nAdaptive bandwidth: 46 CV score: 14937956887 \nAdaptive bandwidth: 36 CV score: 14408561608 \nAdaptive bandwidth: 29 CV score: 14198527496 \nAdaptive bandwidth: 26 CV score: 13898800611 \nAdaptive bandwidth: 22 CV score: 13662299974 \nAdaptive bandwidth: 22 CV score: 13662299974 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbw_CV_fix <- bw.gwr(GDPPC ~ 1,\n                 data= hunan_sp,\n                 approach = \"CV\",\n                 adaptive = FALSE,\n                 kernel = \"bisquare\", #\n                 longlat = TRUE)      # Given that our data is in latlong, the great circle\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFixed bandwidth: 357.4897 CV score: 16265191728 \nFixed bandwidth: 220.985 CV score: 14954930931 \nFixed bandwidth: 136.6204 CV score: 14134185837 \nFixed bandwidth: 84.48025 CV score: 13693362460 \nFixed bandwidth: 52.25585 CV score: Inf \nFixed bandwidth: 104.396 CV score: 13891052305 \nFixed bandwidth: 72.17162 CV score: 13577893677 \nFixed bandwidth: 64.56447 CV score: 14681160609 \nFixed bandwidth: 76.8731 CV score: 13444716890 \nFixed bandwidth: 79.77877 CV score: 13503296834 \nFixed bandwidth: 75.07729 CV score: 13452450771 \nFixed bandwidth: 77.98296 CV score: 13457916138 \nFixed bandwidth: 76.18716 CV score: 13442911302 \nFixed bandwidth: 75.76323 CV score: 13444600639 \nFixed bandwidth: 76.44916 CV score: 13442994078 \nFixed bandwidth: 76.02523 CV score: 13443285248 \nFixed bandwidth: 76.28724 CV score: 13442844774 \nFixed bandwidth: 76.34909 CV score: 13442864995 \nFixed bandwidth: 76.24901 CV score: 13442855596 \nFixed bandwidth: 76.31086 CV score: 13442847019 \nFixed bandwidth: 76.27264 CV score: 13442846793 \nFixed bandwidth: 76.29626 CV score: 13442844829 \nFixed bandwidth: 76.28166 CV score: 13442845238 \nFixed bandwidth: 76.29068 CV score: 13442844678 \nFixed bandwidth: 76.29281 CV score: 13442844691 \nFixed bandwidth: 76.28937 CV score: 13442844698 \nFixed bandwidth: 76.2915 CV score: 13442844676 \nFixed bandwidth: 76.292 CV score: 13442844679 \nFixed bandwidth: 76.29119 CV score: 13442844676 \nFixed bandwidth: 76.29099 CV score: 13442844676 \nFixed bandwidth: 76.29131 CV score: 13442844676 \nFixed bandwidth: 76.29138 CV score: 13442844676 \nFixed bandwidth: 76.29126 CV score: 13442844676 \nFixed bandwidth: 76.29123 CV score: 13442844676 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbw_AIC_fix <- bw.gwr(GDPPC ~ 1,\n                 data= hunan_sp,\n                 approach = \"AIC\",\n                 adaptive = FALSE,\n                 kernel = \"bisquare\", #\n                 longlat = TRUE)      # Given that our data is in latlong, the great circle\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFixed bandwidth: 357.4897 AICc value: 1927.631 \nFixed bandwidth: 220.985 AICc value: 1921.547 \nFixed bandwidth: 136.6204 AICc value: 1919.993 \nFixed bandwidth: 84.48025 AICc value: 1940.603 \nFixed bandwidth: 168.8448 AICc value: 1919.457 \nFixed bandwidth: 188.7606 AICc value: 1920.007 \nFixed bandwidth: 156.5362 AICc value: 1919.41 \nFixed bandwidth: 148.929 AICc value: 1919.527 \nFixed bandwidth: 161.2377 AICc value: 1919.392 \nFixed bandwidth: 164.1433 AICc value: 1919.403 \nFixed bandwidth: 159.4419 AICc value: 1919.393 \nFixed bandwidth: 162.3475 AICc value: 1919.394 \nFixed bandwidth: 160.5517 AICc value: 1919.391 \n```\n\n\n:::\n:::\n\n\n\n### Computing geographically weighted summary statistics\n\nWe will now calculate the summary statistics. Note that your parameters must be the same! If you used adaptive bandwidth, your parameter here should be parameter as well. Otherwise,\n\n![](images/clipboard-86795315.png)\n\nNote, under the list SDF \\> data, we open the table and see:\n\n![](images/clipboard-3601422582.png)\n\nL means Local (note remember that we have 22 nearest neighbours)\n\nLM means local mean, LSD means local standard deviation\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngwstat <- gwss(data= hunan_sp,\n               vars= \"GDPPC\",\n               bw = bw_AIC,\n               kernel = \"bisquare\",\n               adaptive = TRUE,\n               longlat = TRUE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngwstat_df <- as.data.frame(gwstat$SDF)\nhunan_gstat <- cbind(hunan_sf, gwstat_df) # we are appending both tables together based on their index. CAUTION: not to change the sequence of your data during this process.\n```\n:::\n\n\n\n### Visual Map of the Summary Statistics (Mean)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\ntm_shape(hunan_gstat) + #\n  tm_fill(\"GDPPC_LM\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders( alpha = 0.5 ) +\n  tm_layout(main.title = \"Distribution of geographically weighted mean\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.text.size = 0.7,\n            legend.height = 1,\n            legend.width = 1,\n            frame = TRUE)\n```\n\n::: {.cell-output-display}\n![](in-class-ex05_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n\nFurther notes for Take-Home-Exercise01\n\nYou do not need to do the analysis for the whole of Myanmar. It will require an extremely large computational power.\n\nYou can scale down the study area into specific regions, and try to find out what are the localised spatial point patterns.\n\nIn fact, that will allow us to see the localised patterns better. See previous work on Take-Home Exercises.\n",
    "supporting": [
      "in-class-ex05_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}