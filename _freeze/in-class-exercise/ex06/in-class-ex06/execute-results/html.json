{
  "hash": "95ba16d3642042c19cbf0c84a7b78031",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"06 In-class Exercise (Review)\"\nauthor: \"Heng Kuan Xin\"\ndate: 2024-09-23\ndate-modified: \"last-modified\"\n\ntoc: true\ntoc-expand: true\nnumber-sections: true\n\nexecute:\n  eval: true\n  echo: true\n  freeze: true\n  output: true\n  warning: false\n  error: false\n---\n\n\n\n# Recap\n\nLocal Statistics -\\> Test for outliers between states and its neighbours?\n\nTobler's First Law of Geography -\\> i.e basically nearer things are more related than further things\n\nIn this lesson, we will not touch on Spatial Dependency, we will focus on Spatial Autocorrelation.\n\nStatisticians often use it in time series data -- since time series data have a lot of cyclical or seasonal patterns.\n\nInstead of testing for serial stability, in geospatial, we will use autocorrelation for spatial stability. Whether locations are randomly distributed or is it autocorrelated to its neighbours.\n\nTypes of Spatial Autocorrelation Interpretation:\n\n-- Reject null hypo, can infer that there is spatial autocorrelation when interpreting, know that spatial autocorrelation is continuous, just like your correlation coefficients. e.g. in Positive Spatial Autocorrelation, we likely see a range of values from 0 to 1 (clustering is strong when nearer to 1.)\n\n-- When you have more negative spatial autocorrelation, we are likely to see more outliers, that is the checkboard patterns.\n\nBrief history: 1950s to 1960s --\\> '[quantitative geography revolution](https://en.wikipedia.org/wiki/Quantitative_revolution)' Using quantitative methods to measure geographical phenomena.\n\nConfidence Interval:\n\n[![Click on Image for Reference](images/image7-8.jpg){fig-align=\"center\" width=\"468\"}](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2689604/)\n\nWhen we reject the null hypothesis, we can only infer that spatial points are not randomly distributed, we cannot say for sure, or determine that it is really not spatially randomly distributed.\n\nGetis-Ord Global G:\n\nd has to be distance matrix, cannot use proximity matrix.\n\nThe function only tells us whether there are signs of positive or negative clusters –\\> high-high (high value with high value neighbours) clusters and low-low (low value with low value neighbours) clusters.\n\nMeanwhile, there are signs of outliers –\\> high-low, and low-high, which means high value surrounded by low value neighbours and vice versa.\n\n![](images/image7-15.jpg){fig-align=\"center\" width=\"528\"}\n\nThe function only accepts only positive variables, since we are multiplying variables together.\n\nLocal Indicator of Spatial Association (LISA)\n\n-   Break Moran's I into local to come up with LISA\n-   the LISA for each observation gives an indication of the extent of significant spatial clustering of similar values around that observation\n\n# In-class Exercise\n\nIn your Takehome Exercise 2, you have to use [sfdep](https://sfdep.josiahparry.com/), a wrapper of spdep, which is based on **sf** and uses tibble DataFrames, which makes working with the data a lot easier.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(sf, sfdep, tmap, tidyverse)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan_2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")\nhunan_sf <- st_read(\"data/geospatial/\", layer = \"Hunan\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `Hunan' from data source \n  `C:\\hengkuanxin\\SMU_Geospatial_Analytics\\in-class-exercise\\ex06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\nhunan_GDPPC <- left_join(hunan_sf, hunan_2012) %>% select(1:4, 7, 15)\n```\n:::\n\n\n\nTips and Tricks:\n\nWhen using mutate, include argument .before = i, to insert the new attributes before column i. This makes the tibble DataFrame easier to read when we open the table.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwm_q <- hunan_GDPPC %>%\n  mutate( nb = st_contiguity(geometry), # calculate contiguity neighbours as new column called nb\n          wt = st_weights(nb,           # calculate weights as new column called wt\n                          style = \"W\"), # row standardised weights\n          .before = 1)                  # .before makes mutate insert new columns at the front!\n```\n:::\n\n\n\n## Computing Global Moran's I \\[Optional, Since we\\]\n\nglobal_moran() function is used to compute the Moran's I value.\n\nDifferent from spdep package, the output is a tibble data.frame.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmoranI <- global_moran(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt)\nglimpse(moranI)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nList of 2\n $ I: num 0.301\n $ K: num 7.64\n```\n\n\n:::\n:::\n\n\n\nI refers to Moran's I value.\n\nK refers to the average number of neighbours found.\n\n## Performing Global Moran's I Test\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglobal_moran_test(wm_q$GDPPC,\n                  wm_q$nb,\n                  wm_q$wt)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tMoran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n```\n\n\n:::\n:::\n\n\n\n**Check the p-value first!**\n\nThe p-value is smaller than the alpha value if confidence level = 95%. We are therefore able to reject the null hypothesis and we can say that we have enough statistical evidence such that we are 95% confident that clustering is present.\n\n**Then interpret the Moran I statistics**\n\nI is positive, there are signs of clustering.\n\n## Performing Global Moran's I Permutation Test (Repeatedly Test)\n\nIn the real world, in fact you do not need to perform the previous tests. You can just start with the permutation test.\n\nWhat if the Global Moran's I test, under randomisation,\n\nUsually, just a hundred iterations is enough. Note that iterations start from 0. You can also use 999 if need be.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\n\nglobal_moran_perm(wm_q$GDPPC,\n                  wm_q$nb,\n                  wm_q$wt,\n                  nsim = 99)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tMonte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value < 2.2e-16\nalternative hypothesis: two.sided\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlisa <- wm_q %>%\n  mutate(local_moran = local_moran(GDPPC, \n                                   nb, \n                                   wt, \n                                   nsim = 99),\n         .before = 1) %>%\n  unnest(local_moran)\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}