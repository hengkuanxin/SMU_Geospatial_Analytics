{
  "hash": "e3e83f53e535db4d3ab11a1feb8c4826",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"09 In-class Exercise (Review)\"\nauthor: \"Heng Kuan Xin\"\ndate: 2024-10-21\ndate-modified: \"last-modified\"\n\ntoc: true\ntoc-expand: true\nnumber-sections: true\n\nexecute:\n  eval: true\n  echo: true\n  freeze: true\n  output: true\n  warning: false\n  error: false\n---\n\n\n\n## The Code\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(spdep, sp, tmap, sf, ClustGeo, \n               cluster, factoextra, NbClust,\n               tidyverse, GGally)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nshan_sf <- read_rds(\"data/rds/shan_sf.rds\")\nshan_ict <- read_rds(\"data/rds/shan_ict.rds\")\nshan_sf_cluster <- read_rds(\"data/rds/shan_sf_cluster.rds\")\n```\n:::\n\n\n\n## Conventional Hierarchical Clustering\n\nTake note that this is a simplified version of hierarchical clustering.\n\nWe need to first define a proximity matrix.\n\n1.  use base R dist() function to calculate numerical distance between all variables in `shan_ICT`. Note that if your input contains unnecessary variables, you need to filter them out.\n    -   When creating an App, we will usually allow users to specify the variables, and choose the method to be used; refer to [dist() function documentation](https://www.rdocumentation.org/packages/factoextra/versions/1.0.7/topics/dist) for more information.\n2.  use Ward's method for hierarchical clustering to cluster using proximity matrix – outputs a unique hclust object\n3.  Group the results – note that this works together with the hclust() function – on the hclust object\n4.  Use print(groups) to check your output, in terminal or in the code chunks.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nproxmat <- dist(shan_ict, method = \"euclidean\") # calculate numerical distance\nhclust_ward <- hclust(proxmat, method = \"ward.D\") # using Ward's method\ngroups <- as.factor(cutree(hclust_ward, k=6)) #\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(groups)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Mongmit    Pindaya    Ywangan   Pinlaung     Mabein      Kalaw      Pekon \n         1          1          2          1          3          3          1 \n  Lawksawk  Nawnghkio    Kyaukme       Muse     Laihka    Mongnai    Mawkmai \n         3          3          3          4          1          1          5 \n    Kutkai    Mongton    Mongyai  Mongkaing     Lashio    Mongpan     Matman \n         1          1          5          2          3          3          2 \n Tachileik    Narphan   Mongkhet     Hsipaw   Monghsat    Mongmao    Nansang \n         4          5          5          1          5          6          1 \n Laukkaing   Pangsang      Namtu  Monghpyak    Konkyan   Mongping     Hopong \n         4          6          1          3          5          5          1 \nNyaungshwe   Hsihseng     Mongla      Hseni    Kunlong     Hopang    Namhkan \n         3          1          4          3          1          6          4 \n  Kengtung    Langkho    Monghsu   Taunggyi   Pangwaun     Kyethi     Loilen \n         3          3          1          4          6          1          1 \n    Manton   Mongyang    Kunhing  Mongyawng    Tangyan    Namhsan \n         2          6          1          3          1          1 \nLevels: 1 2 3 4 5 6\n```\n\n\n:::\n\n```{.r .cell-code}\nclass(hclust_ward)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"hclust\"\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nshan_sf_cluster <- cbind(shan_sf,\n                         as.matrix(groups) # convert to a matrix or data table as.dt so                                                that you can append to shan_sf\n                         ) %>%\n  rename('CLUSTER' = 'as.matrix.groups.') %>% # tidy up by using meaningful column names\n  select(-c(3:4, 7:9)) %>% # -c drops away columns; filter away all unwanted columns\n  rename(TS = TS.x) # tidy up by using meaningful column names\n```\n:::\n\n\n\nWhy tidy up? Because the output will look like this:\n\n![](images/clipboard-1933921546.png){fig-align=\"center\" width=\"624\"}\n\nCarefully look at your data output and use things like `rename('NAME' = 'OldName')` and `select(-c(x:y))`.\n\nuse the following to ensure your figure outputs look readable:\n\n`#| fig-height: 7 #| fig-width: 12`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(hclust_ward, cex=0.6)\nrect.hclust(hclust_ward, k=6 , border = 2:5)\n```\n\n::: {.cell-output-display}\n![](in-class-ex09_files/figure-html/unnamed-chunk-6-1.png){width=1152}\n:::\n:::\n\n\n\n### Quick Plot of the Clustering Results\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqtm(shan_sf_cluster, \"CLUSTER\") # note base R only has 16 colours, beyond that, you have to use your own colour scheme.\n```\n\n::: {.cell-output-display}\n![](in-class-ex09_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n## Spatially Constrained Hierarchical Clustering\n\nNote that **spdep** **now allows sf objects as inputs**, so you no longer need to convert sf objects to sp objects before inputting.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshan.nb <- poly2nb(shan_sf)\nsummary(shan.nb)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(st_geometry(shan_sf),\n     border = grey(.5))\n\npts <- st_coordinates(st_centroid(shan_sf))\n\nplot(shan.nb,\n    pts,\n    col=\"blue\",\n    add=TRUE)\n```\n\n::: {.cell-output-display}\n![](in-class-ex09_files/figure-html/unnamed-chunk-9-1.png){width=1152}\n:::\n:::\n\n\n\n### Computing Minimum Spanning Tree\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlcosts <- nbcosts(shan.nb, shan_ict)\n```\n:::\n\n\n\n### Computing the Spatial Weights\n\nNote we are fixing the style as \"B\", referring to the documentation:\n\nDefault value for style is \"W\"\n\nB is the basic binary coding, W is row standardised (sums over all links to n), C is globally standardised (sums over all links to n), U is equal to C divided by the number of neighbours (sums over all links to unity), while S is the variance-stabilizing coding scheme.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshan.w <- nb2listw(shan.nb,\n                   lcosts,\n                   style=\"B\") # this is important, ensure binary\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nshan.mst <- mstree(shan.w)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(st_geometry(shan_sf),\n     border = grey(.5))\n\npts <- st_coordinates(st_centroid(shan_sf))\n\nplot(shan.mst,\n    pts,\n    col=\"blue\",\n    cex.lab=0.7,\n    cex.circles=0.005,\n    add=TRUE)\n```\n\n::: {.cell-output-display}\n![](in-class-ex09_files/figure-html/unnamed-chunk-13-1.png){width=1152}\n:::\n:::\n\n\n\n### Computing Spatially Constrained Clusters using SKATER method\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nskater.clust6 <- skater(edges = shan.mst[,1:2],\n                        dat = shan_ict,\n                        method = \"euclidean\",\n                        ncuts = 5)\n```\n:::\n\n\n\n### Visualising the SKATER Tree\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(st_geometry(shan_sf),\n     border = gray(0.5))\n\nplot(skater.clust6,\n     pts,\n     cex.lab=0.7,\n     groups.colours=c(\"red\",\"green\",\"blue\",\"brown\",\"pink\"),\n     cex.circles=0.005,\n     add=TRUE # this parameter plots the 2nd plot over the 1st geometry plot\n)\n```\n\n::: {.cell-output-display}\n![](in-class-ex09_files/figure-html/unnamed-chunk-15-1.png){width=1152}\n:::\n:::\n\n\n\n::: callout-note\n## Useful Tip\n\nIn the code chunk below, we want to convert groups_mat into character data type, rather than a numerical data type. We can use `as.factor()`, which will automatically sort data by alphabetical or numerical form, which conveniently outputs in a sorted manner.\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# extract the groups/cluster as a matrix\ngroups_mat <- as.matrix(skater.clust6$groups)\n\n# so that we can cbind it with shan_sf_cluster\n# convert numerical data type to factor (which is of type character) using as.factor() \n# note: avoid using as.character() as it can result in unsorted results.\nshan_sf_spatialcluster <- cbind(shan_sf_cluster, \n                                as.factor(groups_mat)) %>%\n  rename('skater_CLUSTER' = 'as.factor.groups_mat.')\n\nqtm(shan_sf_spatialcluster, \"skater_CLUSTER\")\n```\n\n::: {.cell-output-display}\n![](in-class-ex09_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n\n## Spatially Constrained ClusteringL ClustGeo Method\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndist <- st_distance(shan_sf, shan_sf) # specify origin and destination\ndistmat <- as.dist(dist) # convert to dist matrix\n```\n:::\n\n\n\n### Cluster Graphs\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# This code chunk plots the proximity weights and distance weights against one another\n# range of alpha is used as such = seq(startOfRange, endOfRange, interval)\n\n# The function outputs 2 graphical plots\n# The difference between them is this: 1st plot gives you the raw values, 2nd plot is min-max standardised.\ncr <- choicealpha(proxmat, distmat, \n                  range.alpha = seq(0, 1, 0.1), \n                  K=6, graph = TRUE)\n```\n\n::: {.cell-output-display}\n![](in-class-ex09_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](in-class-ex09_files/figure-html/unnamed-chunk-18-2.png){width=672}\n:::\n:::\n\n\n\nUse the first graph to determine when is the optimal cutoff alpha value. The closer the gap between line D0 and D1, the better. A lower alpha value means a greater\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclustG <- hclustgeo(proxmat, distmat, alpha = 0.2)\ngroups <- as.factor(cutree(clustG, k=6))\nshan_sf_clustGeo <- cbind(shan_sf, \n                          as.matrix(groups)) %>%\n  rename(\"clustGeo\" = \"as.matrix.groups.\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nqtm(shan_sf_clustGeo, \"clustGeo\")\n```\n\n::: {.cell-output-display}\n![](in-class-ex09_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\n\n### Visualising the Clusters using Parallel Coordinates\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggparcoord(data = shan_sf_clustGeo, \n           columns = c(17:21), \n           scale = \"globalminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of ICT Variables by Cluster\") +\n  facet_grid(~ clustGeo) + # another choice is facet_wrap()\n  theme(axis.text.x = element_text(angle = 30))\n```\n\n::: {.cell-output-display}\n![](in-class-ex09_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n\nHow do we interpret this?\n\nThe thick black line within each boxplot refers to the 50th percentile.\\\nEach line connecting the box plots is an observation. In this case, each observation represents each province(? or township) in the Shan state. If a particular cluster has less observations, it also means that cluster is small, and has less provinces.\n\nIf a cluster has a relatively low value for LLPHONE_PR, we can infer that the residents in that cluster has a relatively low ownership of land line phones.\n\nSome characteristics can be seen throughout multiple clusters, like the low values for LLPHONE_PR and COMPUTER_PR throughout all clusters. Meanwhile, some characteristics uniquely define a cluster, like the particularly high RADIO_PR value of cluster 4.\n\n# Conclusion\n\nWhen do we use SKATER method and ClustGeo method?\n\nSKATER method is a hard method, that is, you cannot control the weight(?) of the spatial attributes. ClustGeo method allows you to control the relative weights between the weight of the spatial attributes vs non-spatial attributes, allow you to control the effect of spatial constraints on the final clustering result.\n\nHow is this different from the univariate LISA clustering we used in Takehome Exercise 2?\n\nThis method allows you to consider multiple variables at the same time for clustering, rather than using a single variable.\n",
    "supporting": [
      "in-class-ex09_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}