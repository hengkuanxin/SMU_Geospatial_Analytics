{
  "hash": "fa346c4d347978b39763bb1436744e50",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"11 In-class Exercise (Review)\"\nauthor: \"Heng Kuan Xin\"\ndate: 2024-11-04\ndate-modified: \"last-modified\"\n\ntoc: true\ntoc-expand: true\nnumber-sections: true\n\nexecute:\n  eval: false\n  echo: true\n  freeze: true\n  output: true\n  warning: false\n  error: false\n---\n\n\n\n# In class exercise code\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(tidyverse, sf, tmap, httr, performance)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfolder_path <- \"data/aspatial\"\n\n# Read all files starting with realis + ending with .csv\nfile_list <- list.files( path = folder_path,\n                         pattern = \"^realis.*\\\\.csv$\",\n                         full.names = TRUE)\n\n# Functions that return data frames, use read_csv(), also appends data together \nrealis_data <- file_list %>%\n  map_dfr(read_csv)\n```\n:::\n\n\n\nWhen you are using any Postal Code, make sure it is read as character, but not num or int which will result in truncated values especially when a postal code starts with 0.\n\nNote that the date field is in chr rather than a date format. We need to fix this.\n\n## Data wrangling\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncondo_resale <- realis_data %>%\n  mutate(`Sale Date` = dmy(`Sale Date`)) %>% # convert to d-m-y \n  filter(`Type of Sale` == \"Resale\" &        # combination of two logical search using '&'\n           `Property Type` == \"Condominium\")\n```\n:::\n\n\n\n## Query OneMap (Geocoding from Postal Codes)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Select a unique list of postal codes\npostcode <- unique(condo_resale$`Postal Code`)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nurl <- \"https://onemap.gov.sg/api/common/elastic/search\"\nfound <- data.frame()\nnot_found <- data.frame()\n\n# Do geocoding for postcodes rather than doing it for every row in the condo_resale data\nfor (postcode in postcode){\n  query <- list('searchVal'=postcode, 'returnGeom'='Y',\n                'getAddrDetails'='Y', 'pageNum'='1')\n  \n  res <- GET(url, query=query)\n  if ((content(res)$found) != 0){\n    found <- rbind(found, data.frame(content(res))[4:13])\n  } else {\n    not_found = data.frame(postcode)\n  }\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfound <- found %>%\n  select(c(6:8)) %>%\n  rename(POSTAL = `results.POSTAL`,\n         XCOORD = `results.X`,\n         YCOORD = `results.Y`)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncondo_resale_geocoded <- left_join(condo_resale, found, \n                                   by = c(\"Postal Code\" = \"POSTAL\"))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncondo_resale_sf <- st_as_sf(condo_resale_geocoded,\n                            coords = c(\"XCOORD\", \"YCOORD\"),\n                            crs= 3414\n                            )\n```\n:::\n\n\n\n## Handling Overlapping Points by Jittering\n\nCheck if there are overlapping points\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Add a column to see if overlap is TRUE or FALSE\noverlapping_points <- condo_resale_sf %>% mutate(overlap = lengths(st_equals(., .)) > 1)\n```\n:::\n\n\n\nIf there are overlapping points, then we need to jitter, and repeatedly do so.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Since there are overlapping points, we will shift the points by 2 metres\ncondo_resale_sf <- condo_resale_sf %>% st_jitter(amount = 2)\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}