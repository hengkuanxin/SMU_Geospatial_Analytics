{
  "hash": "c1f96f1407abc58202538c7a5b2c474d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"01 Take Home Exercise 1\"\nsubtitle: \"Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar\"\nauthor: \"Heng Kuan Xin\"\ndate: 2024-09-04\ndate-modified: \"last-modified\"\n\n# toc: true\n#toc-expand: true\nnumber-sections: true\n\nexecute:\n  eval: true\n  echo: true\n  freeze: true\n  output: true\n  warning: false\n  error: false\n---\n\n\n\nData sets:\n\n-   [Data Set Columns Information](https://acleddata.com/knowledge-base/codebook/)\n-   [Data Set Myanmar Overview](https://acleddata.com/knowledge-base/acled-methodology-and-coding-decisions-around-political-violence-and-demonstrations-in-myanmar/)\n-   Categories by Event Type: Battles, Explosion/Remote violence, Strategic developments, and Violence against civilians.\n-   In terms of study period, students should focus on quarterly armed conflict events from January 2021 until June 2024.\n\nImporting Data sets:\n\nBullet points:\n\n-   point 1 on lesson 1 (dataset: administrative boundary data -\\> sf tibble dataframe)\n-   point 2 and 3 last week lesson 3 (dataset: ACLED point data -\\> derive KDE & 2nd-Order Point Pattern Analysis)\n    -   **Caution!** dataset is very large! For point 2, it may take 8 mins. For point 3, it may take half a day.\n    -   Make sure to estimate the time, effort you require -\\> plan ahead\n\nCase Study:\n\nHistory of Myanmar Armed Conflict:\n\nCurrent Situation:\n\nStudy Area:\n\nFocus and Objective:\n\nAnalysis Methods Used:\n\nOur main purpose here this time is to study the **quarterly spatio-temporal distribution of armed conflict events in Myanmar**. Therefore, the focus is mainly on the **types of events**, **date of events**, and the **location of events**. We will not be focusing on other matters in this exercise.\n\n# Import the Necessary\n\n## Import Libraries / Packages\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(tidyverse, sf, spatstat, ggplot2, tmap, gifski)\n```\n:::\n\n\n\n## Import Raw Data\n\n### ACLED Data Set\n\nBefore we start manipulating the data, it is important that we understand what each data column and data type mean and how valuable it is for our analysis.\n\nTo begin, let us refer to the [ACLED data set codebook](https://acleddata.com/acleddatanew/wp-content/uploads/dlm_uploads/2023/06/ACLED_Codebook_2023.pdf)\n\nThe data was retrieved from the ACLED data portal. Specifically, the following types of data was retrieved:\n\n1.  `violence-against-civilians.csv`\n2.  `strategic-developments.csv`\n3.  `battles.csv`\n4.  `explosion-or-remoteviolence.csv`\n\nIn terms of event types, four main event types were retrieved: **Battles**, **Explosion/Remote violence**, **Strategic developments**, and **Violence against civilians**.\n\nIn terms of study period, we are focused on quarterly armed conflict events from **January 2021** until **June 2024.**\n\nThe code chunk below imports the data for our analysis.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nviolence_against_civilians <- read_csv(\"data/raw/aspatial/ACLED/violence-against-civilians.csv\") %>%\n  st_as_sf(coords =c(\n    \"longitude\", \"latitude\"),\n    crs=4326) %>%\n    st_transform(crs = 32647) %>%\n    mutate(event_date = dmy(event_date))\n\nstrategic_developments <- read_csv(\"data/raw/aspatial/ACLED/strategic-developments.csv\") %>%\n  st_as_sf(coords =c(\n    \"longitude\", \"latitude\"),\n    crs=4326) %>%\n    st_transform(crs = 32647) %>%\n    mutate(event_date = dmy(event_date))\n\nbattles <- read_csv(\"data/raw/aspatial/ACLED/battles.csv\") %>%\n  st_as_sf(coords =c(\n    \"longitude\", \"latitude\"),\n    crs=4326) %>%\n    st_transform(crs = 32647) %>%\n    mutate(event_date = dmy(event_date))\n\nexplosion_or_remoteviolence <- read_csv(\"data/raw/aspatial/ACLED/explosion-or-remoteviolence.csv\") %>%\n  st_as_sf(coords =c(\n    \"longitude\", \"latitude\"),\n    crs=4326) %>%\n    st_transform(crs = 32647) %>%\n    mutate(event_date = dmy(event_date))\n```\n:::\n\n\n\n### Administrative Boundary Dataset\n\n[![Myamar's Administrative Division Hierachy (source: Wikipedia)](images/clipboard-2034245623.png){fig-alt=\"Myamar's Administrative Division Hierachy\" fig-align=\"center\"}](https://en.wikipedia.org/wiki/Administrative_divisions_of_Myanmar)\n\nIn this exercise, we will only analyse geographical distribution of point data up to the 3rd degree administrative division, i.e. up to Township level.\n\nThe following data are the administrative boundaries of Myanmar, obtained from [MIMU Vector Boundaries](https://geonode.themimu.info/layers/?limit=100&offset=0&type__in=vector&category__identifier__in=boundaries), a common data and information repository by a NGO (related to UN).\n\nWhile many data formats exist, we will choose `.csv` files when downloading as they are easier to read and work with. A suitable alternative is the `.shp` file format available on the website.\n\nDatasets:\n\n-   `mmr_polbnda_adm0_250k_mimu_1.csv` National boundary of Myanmar\n\n-   `mmr_polbnda_adm1_250k_mimu_1.csv` **Region/State/Union Territory** level boundary of Myanmar\n\n-   `mmr_polbnda2_adm1_250k_mimu_1.csv` **Sub-Region/State/Union Territory** level boundary of Myanmar; Sub-region divides a region into smaller divisions, such as \"Bago (East)\" and \"Bago (West)\" instead of \"Bago\"\n\n-   `mmr_polbnda_adm2_250k_mimu.csv` **District/Self-Administered Zone** level boundary of Myanmar\n\n-   `mmr_polbnda_adm3_250k_mimu_1.csv` **Township** level boundary of Myanmar\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# kml file not easy to read due to nested columns for attributes data\nadmin_0 <- read_csv(\"data/raw/geospatial/mimu_admin_boundary/mmr_polbnda_adm0_250k_mimu_1.csv\") %>%\n  st_as_sf(wkt = \"the_geom\",\n    crs=4326) %>%\n    st_transform(crs = 32647)\n    \nadmin_1 <- read_csv(\"data/raw/geospatial/mimu_admin_boundary/mmr_polbnda_adm1_250k_mimu_1.csv\") %>%\n  st_as_sf(wkt = \"the_geom\",\n    crs=4326) %>%\n    st_transform(crs = 32647)\n\nadmin_1_sub <- read_csv(\"data/raw/geospatial/mimu_admin_boundary/mmr_polbnda2_adm1_250k_mimu_1.csv\") %>%\n  st_as_sf(wkt = \"the_geom\",\n    crs=4326) %>%\n    st_transform(crs = 32647)\n\nadmin_2 <- read_csv(\"data/raw/geospatial/mimu_admin_boundary/mmr_polbnda_adm2_250k_mimu.csv\") %>%\n  st_as_sf(wkt = \"the_geom\",\n    crs=4326) %>%\n    st_transform(crs = 32647)\n\nadmin_3 <- read_csv(\"data/raw/geospatial/mimu_admin_boundary/mmr_polbnda_adm3_250k_mimu_1.csv\") %>%\n  st_as_sf(wkt = \"the_geom\",\n    crs=4326) %>%\n    st_transform(crs = 32647)\n```\n:::\n\n\n\n### Quick Plot To Visualise Data Sets\n\nBefore we continue, let's get a visual sense of the data by plotting it on a map to ensure we are working with the right dataset. In this step, we will also try to see if there are any erranous data that we have to clean later.\n\n**Check the Administrative Boundaries Data Set**\n\nFrom the left to right, we are able to see the increase in degree of administrative boundary division; respectively, they represent\n\n1.  \"**National**\",\n2.  \"**Region/State/Union Territory**\",\n3.  \"**Sub-Region/State/Union Territory**\",\n4.  \"**District/Self-Administered Zone**\", and\n5.  \"**Township**\"\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\ntmap_style(\"classic\")\n\ntmap_arrange(\n  qtm(admin_0, title=\"National\"), \n  qtm(admin_1, title=\"Region/State/Union\\nTerritory\"), \n  qtm(admin_1_sub, title=\"Sub-Region/State/Union\\nTerritory\"), \n  qtm(admin_2, title=\"District/Self-\\nAdministered Zone\"), \n  qtm(admin_3, title=\"Township\"), \n  ncol = 5\n)\n```\n:::\n\n\n\n![Plot of Admin Boundaries of Myanmar Raw Data](images/unnamed-chunk-4-1.png){fig-align=\"center\"}\n\n**Conclusion: Administrative Boundaries Looks Okay**\n\nLooking at both the attribute table and the plot, the administrative boundaries data seem quite alright, so we might not need to do any cleaning. Anyway, the precision of the polygons it not as critical as the precision of the ACLED data (which will be used for our spatial point patterns analysis).\n\n**Check ACLED Data Set**\n\nSince the ACLED data is our main focus, let us now plot the data points onto the map of Myanmar.\n\nIn the code chunk below, we plot out the various types of data points from ACLED, namely (from left to right):\n\n1.  \"**Violence against Civilians**\",\n2.  \"**Strategic Developments**\",\n3.  \"**Explosion/Remote Violence**\", and\n4.  \"**Battles**\"\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\ntmap_style(\"cobalt\")\n\ntmap_arrange(\n  qtm(admin_0) + qtm(violence_against_civilians, title=\"Violence against\\nCivilians\"), \n  qtm(admin_0) + qtm(strategic_developments, title=\"Strategic\\nDevelopments\"), \n  qtm(admin_0) + qtm(explosion_or_remoteviolence, title=\"Explosion/\\nRemote Violence\"), \n  qtm(admin_0) + qtm(battles, title=\"Battles\"), \n  ncol = 4\n)\n```\n:::\n\n\n\n![Plot of ACLED Raw Points Data](images/unnamed-chunk-5-1.png){fig-align=\"center\"}\n\n**Observation: ACLED Data Set needs further study, may need to clean**\n\nNothing looks very off at a glance, but we should look into the attribute columns to see if the data set is truly clean. Let us refer to the [codebook](https://acleddata.com/acleddatanew/wp-content/uploads/dlm_uploads/2023/06/ACLED_Codebook_2023.pdf) again, and see if we can spot any potentially critical problems.\n\nReferring to the attribute columns and the codebook, we can see potentially critical concerns:\n\n1.  **geo_precision** – The precision of the geocoded coordinates ranges from code 1 to code 3; where lower level implies higher precision.\n    -   In particular, \"\\[if\\] a larger region is mentioned, the closest natural location noted in reporting (like “border area,” “forest,” or “sea,” among others) – or a provincial capital is used if no other information at all is available – is chosen to represent the region, and ‘Geo-precision’ code 3 is recorded.\" (page 36)\n2.  **time_precision** – The precision of the recorded datetime ranges from code 1 to code 3; where lower level implies higher precision.\n    -   In particular, \"if the source material only indicates that an event took place sometime during a month (i.e. in the past two or three weeks, or in January), without reference to the particular date, the month mid-point is chosen. If the beginning or end of the month is noted, the first and last date is used, respectively. In both of these cases, a ‘Time precision’ code of 3 is recorded.\" (page 36-37)\n\nIn both cases, ACLED do not include events with less spatial or temporal precision.\n\n**Identifying code 3 precisions**\n\nGiven that precision of our point data is crucial to our spatial-temporal point patterns analysis, we should see how much of our data is imprecise, and whether we should keep the imprecise data points.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Violence against Civilians\nviolence_against_civilians %>% count(geo_precision)\nviolence_against_civilians %>% count(time_precision)\n\n# Strategic Developments\nstrategic_developments %>% count(geo_precision)\nstrategic_developments %>% count(time_precision)\n\n# Explosion or Remote Violence\nexplosion_or_remoteviolence %>% count(geo_precision)\nexplosion_or_remoteviolence %>% count(time_precision)\n\n# Battles\nbattles %>% count(geo_precision)\nbattles %>% count(time_precision)\n```\n:::\n\n\n\n**Conclusion: Drop time and spatial precision code 3 data values from ACLED Data set**\n\nFrom this analysis, we can see that the count of precision code 3 in both time and spatial precision is actually very low, it might be worth dropping the values with low time and spatial precision.\n\nLet us start cleaning the data\n\n## Data Cleaning\n\nLet us filter out the data we want (time_precision and geo_precision codes \\< 3), and see how many rows we have removed.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Extract all rows where either geo_precision or time_precision is not = 3 \nviolence_against_civilians_filtered <- violence_against_civilians %>%\n  filter(!(geo_precision == 3 | time_precision == 3))\n\nstrategic_developments_filtered <- strategic_developments %>%\n  filter(!(geo_precision == 3 | time_precision == 3))\n\nexplosion_or_remoteviolence_filtered <- explosion_or_remoteviolence %>%\n  filter(!(geo_precision == 3 | time_precision == 3))\n\nbattles_filtered <- battles %>%\n  filter(!(geo_precision == 3 | time_precision == 3))\n\ncat(\"Number of rows dropped:\", nrow(violence_against_civilians) - nrow(violence_against_civilians_filtered) , \"\\n\")\ncat(\"Number of rows dropped:\", nrow(strategic_developments) - nrow(strategic_developments_filtered) , \"\\n\")\ncat(\"Number of rows dropped:\", nrow(explosion_or_remoteviolence) - nrow(explosion_or_remoteviolence_filtereed) , \"\\n\")\ncat(\"Number of rows dropped:\", nrow(battles) - nrow(battles_filtered) , \"\\n\")\n```\n:::\n\n\n\n**Overall, the result seems satisfactory**. Let us continue with our data cleaning. by keeping only columns that are important for our analysis.\n\nWe will only **keep the following columns** as other columns are not relevant to our study:\n\n-   event_date,\n-   year,\n-   disorder_type,\n-   sub_event_type,\n-   admin1,\n-   admin2,\n-   admin3\n-   (also including the geometry data)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfilter_columns <- c(\"event_date\",\"year\",\"disorder_type\",\"sub_event_type\",\"admin1\",\"admin2\",\"admin3\")\n\nviolence_against_civilians_filtered <- violence_against_civilians_filtered %>%\n  select(all_of(filter_columns))\n\nstrategic_developments_filtered <- strategic_developments_filtered %>%\n  select(all_of(filter_columns))\n\nexplosion_or_remoteviolence_filtered <- explosion_or_remoteviolence_filtered %>%\n  select(all_of(filter_columns))\n\nbattles_filtered <- battles_filtered %>%\n  select(all_of(filter_columns))\n```\n:::\n\n\n\n## Data Extraction\n\n### Extract Quarterly Data from ACLED Dataset\n\nNow, since we want to analyse the quarterly events, let us add a new column within the tibble DataFrame called **quarter** to represent the quarter of each date in numerical format, e.g. (1, 2, 3, or 4). After that, let us create another column called **year_quarter** to represent the quarter of every year in string format, e.g. (\"2021-Q1\", \"2023-Q4\").\n\nThe package we will be using here is called lubridate, a package within the tidyverse library.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nviolence_against_civilians_filtered <- violence_against_civilians_filtered %>% \n  mutate(quarter = quarter(event_date)) %>%\n  mutate(year_quarter = paste0(year, \"-Q\", quarter))\n\nstrategic_developments_filtered <- strategic_developments_filtered %>% \n  mutate(quarter = quarter(event_date)) %>%\n  mutate(year_quarter = paste0(year, \"-Q\", quarter))\n\nexplosion_or_remoteviolence_filtered <- explosion_or_remoteviolence_filtered %>% \n  mutate(quarter = quarter(event_date)) %>%\n  mutate(year_quarter = paste0(year, \"-Q\", quarter))\n\nbattles_filtered <- battles_filtered %>% \n  mutate(quarter = quarter(event_date)) %>%\n  mutate(year_quarter = paste0(year, \"-Q\", quarter))\n```\n:::\n\n\n\n## Export Data Sets (RDS file format)\n\nBefore we continue, let's export our cleaned data sets so that our changes are saved. **We will export the data sets in the RDS format.**\n\nRDS stands for R Data Serialization. It’s a binary serialization format in R used to save R objects to a file. This format preserves the class, attributes, and structure of the R object, making it useful for saving and loading data while maintaining its integrity.\n\n::: {.callout-tip collapse=\"true\"}\nBy exporting the data, and importing it again, it also serves as a *checkpoint* for our analysis. We will be able to stop loading old variables in our environment, and only load in the new variables. It also allows readers who are trying to reproduce the analysis verify their own results with our analysis results.\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Save the sf object to an RDS file\nsaveRDS(violence_against_civilians_filtered, \"data/rds/violence_against_civilians.rds\")\nsaveRDS(strategic_developments_filtered, \"data/rds/strategic_developments.rds\")\nsaveRDS(explosion_or_remoteviolence_filtered, \"data/rds/explosion_or_remoteviolence.rds\")\nsaveRDS(battles_filtered, \"data/rds/battles.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Save the sf object to an RDS file\nsaveRDS(admin_0, \"data/rds/admin_boundary_national.rds\")\nsaveRDS(admin_1, \"data/rds/admin_boundary_region-state-unionTerritory.rds\")\nsaveRDS(admin_1_sub, \"data/rds/admin_boundary_subRegion-state-unionTerritory.rds\")\nsaveRDS(admin_2, \"data/rds/admin_boundary_district-selfAdministeredZone.rds\")\nsaveRDS(admin_3, \"data/rds/admin_boundary_township.rds\")\n```\n:::\n\n\n\nNow, let's continue to the next section.\n\n# Import Data Sets (RDS file format)\n\nLet us import the data sets back.\n\nThe code chunk below imports the cleaned and filtered ACLED data that was previously exported into RDS file format.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nviolence_against_civilians <- readRDS(\"data/rds/violence_against_civilians.rds\")\nstrategic_developments <- readRDS(\"data/rds/strategic_developments.rds\")\nexplosion_or_remoteviolence <- readRDS(\"data/rds/explosion_or_remoteviolence.rds\")\nbattles <- readRDS(\"data/rds/battles.rds\")\n```\n:::\n\n\n\nThe code chunk below imports the transformed admin boundaries data that was previously exported into RDS file format. Note that we have yet to decide on a study area, so we will continue to import all the data for our analysis.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nadmin_0 <- readRDS(\"data/rds/admin_boundary_national.rds\")\nadmin_1 <- readRDS(\"data/rds/admin_boundary_region-state-unionTerritory.rds\")\nadmin_1_sub <- readRDS(\"data/rds/admin_boundary_subRegion-state-unionTerritory.rds\")\nadmin_2 <- readRDS(\"data/rds/admin_boundary_district-selfAdministeredZone.rds\")\nadmin_3 <- readRDS(\"data/rds/admin_boundary_township.rds\")\n```\n:::\n\n\n\n## Identify Study Area(s)\n\n### Visualise ACLED data\n\nNow that we have categorised the ACLED points data into specific yearly quarters, let us plot them onto the map of myanmar to see if there are any obvious patterns.\n\nSo far, we can have up to 14 temporal categories, with 4 quarters per year in **Year 2021, 2022, 2023**, and 2 quarters in the **first half of 2024**.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\ntmap_style(\"classic\")\n\ntm_shape(admin_1) +\n  tm_polygons() +\n  tm_shape(violence_against_civilians) +\n  tm_dots(size= 0.05, col = \"black\", alpha = 0.5) +\n  tm_facets(by = \"year_quarter\",\n              free.coords = FALSE,\n              drop.units = TRUE) +\n  tm_layout(main.title=\"Violence Against Civilians (Quarterly)\")\n\ntm_shape(admin_1) +\n  tm_polygons() +\n  tm_shape(strategic_developments) +\n  tm_dots(size= 0.05, col = \"black\", alpha = 0.5) +\n  tm_facets(by = \"year_quarter\",\n              free.coords = FALSE,\n              drop.units = TRUE) +\n  tm_layout(main.title=\"Strategic Developments (Quarterly)\")\n\ntm_shape(admin_1) +\n  tm_polygons() +\n  tm_shape(explosion_or_remoteviolence) +\n  tm_dots(size= 0.05, col = \"black\", alpha = 0.5) +\n  tm_facets(by = \"year_quarter\",\n              free.coords = FALSE,\n              drop.units = TRUE) +\n  tm_layout(main.title=\"Explosion/Remote Violence (Quarterly)\")\n\ntm_shape(admin_1) +\n  tm_polygons() +\n  tm_shape(battles) +\n  tm_dots(size= 0.05, col = \"black\", alpha = 0.5) +\n  tm_facets(by = \"year_quarter\",\n              free.coords = FALSE,\n              drop.units = TRUE) +\n  tm_layout(main.title=\"Battles (Quarterly)\")\n```\n:::\n\n\n\n![](images/unnamed-chunk-14-1.png){fig-align=\"center\"}\n\n![](images/unnamed-chunk-14-2.png){fig-align=\"center\"}\n\n![](images/unnamed-chunk-14-3.png){fig-align=\"center\"}\n\n![](images/unnamed-chunk-14-4.png){fig-align=\"center\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\n\nmap_quarterly_ViolAgstCiv <- tm_shape(admin_1) +\n  tm_style(\"white\") +\n  tm_polygons() +\n  tm_shape(violence_against_civilians) +\n  tm_dots(size= 0.1) + # make sizes a bit bigger so that it can be seen\n  tm_facets(along = \"year_quarter\", # 1 separate map for each year quarter\n              free.coords = FALSE,\n              drop.units = TRUE)\n\nmap_quarterly_StratDev <- tm_shape(admin_1) +\n  tm_style(\"white\") +\n  tm_polygons() +\n  tm_shape(strategic_developments) +\n  tm_dots(size= 0.1) + # make sizes a bit bigger so that it can be seen\n  tm_facets(along = \"year_quarter\", # 1 separate map for each year quarter\n              free.coords = FALSE,\n              drop.units = TRUE)\n\nmap_quarterly_ExploOrRemoViol <- tm_shape(admin_1) +\n  tm_style(\"white\") +\n  tm_polygons() +\n  tm_shape(explosion_or_remoteviolence) +\n  tm_dots(size= 0.1) + # make sizes a bit bigger so that it can be seen\n  tm_facets(along = \"year_quarter\", # 1 separate map for each year quarter\n              free.coords = FALSE,\n              drop.units = TRUE)\n\nmap_quarterly_Battles <- tm_shape(admin_1) +\n  tm_style(\"white\") +\n  tm_polygons() +\n  tm_shape(battles) +\n  tm_dots(size= 0.1) + # make sizes a bit bigger so that it can be seen\n  tm_facets(along = \"year_quarter\", # 1 separate map for each year quarter\n              free.coords = FALSE,\n              drop.units = TRUE)\n\ntmap_animation(map_quarterly_ViolAgstCiv,\n               filename=\"images/quarterly_violenceAgainstCivilians.gif\", delay=100)\n\ntmap_animation(map_quarterly_StratDev,\n               filename=\"images/quarterly_strategicDevelopments.gif\", delay=100)\n\ntmap_animation(map_quarterly_ExploOrRemoViol,\n               filename=\"images/quarterly_explosionOrRemoteViolence.gif\", delay=100)\n\ntmap_animation(map_quarterly_Battles,\n               filename=\"images/quarterly_battles.gif\", delay=100)\n```\n:::\n\n\n\n![Quarterly events: Violence Against Civilians](images/quarterly_violenceAgainstCivilians.gif){fig-alt=\"Quarterly events: Violence Against Civilians\" fig-align=\"center\" width=\"200\"}\n\n![Quarterly events: Strategic Developments](images/quarterly_strategicDevelopments.gif){fig-alt=\"Quarterly events: Strategic Developments\" fig-align=\"center\" width=\"200\"}\n\n![Quarterly events: Explosion / Remote Violence](images/quarterly_explosionOrRemoteViolence.gif){fig-alt=\"Quarterly events: Explosion / Remote Violence\" fig-align=\"center\" width=\"200\"}\n\n![Quarterly events: Battles](images/quarterly_battles.gif){fig-alt=\"Quarterly events: Battles\" fig-align=\"center\" width=\"200\"}\n\n### Decision: Study Area(s) in the Western Region (Rakhine, Chin, Magway)\n\n**Deciding on a Study Area(s)**\n\nAfter a brief observation of the points data, I've decided to focus on the western regions/states which seems to have quite a variety of point patterns throughout time. According to the map generated by the code chunk below, we can see that the places are called **Rakhine**, **Chin**, and **Magway**. Throughout the data sets, we see quite a number of conflict events occurring in the area in northern Rakhine. Let us focus on this area for our analysis hereon.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntm_shape(admin_1) +\n  tm_style(\"white\") +\n  tm_polygons(\"ST\", palette = \"Set3\", title = \"States/Regions\") +\n  tm_shape(st_centroid(admin_1)) + # Find the centroids\n  tm_text(\"ST\", size = 0.6, col = \"black\", shadow = TRUE, just=\"center\") + # Add labels at centroids\n  tm_layout(title = \"Administrative Boundaries Level 1\",\n            legend.outside = TRUE)\n```\n:::\n\n\n\n![](images/unnamed-chunk-16-1.png)\n\n# Preparing Study Area(s) Data\n\n## Select Study Area(s) Boundary\n\nLet us also select the study area(s) boundary\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstudyarea <- admin_1 %>% filter(ST %in% c(\"Rakhine\", \"Chin\", \"Magway\"))\nqtm(studyarea)\n```\n:::\n\n\n\n![](images/unnamed-chunk-17-1.png)\n\n## Select Study Area(s) ACLED Data\n\nSince ACLED already came with attributes admin1, admin2, and admin3, let us use it to help us filter the points data.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Violence Against Civilians\nstudyarea_vac <- violence_against_civilians %>% \n  filter(admin1 %in% c(\"Rakhine\", \"Chin\", \"Magway\"))\n\n# Strategic Deployment\nstudyarea_stdp <- strategic_developments %>% \n  filter(admin1 %in% c(\"Rakhine\", \"Chin\", \"Magway\"))\n\n# Explosions / Remote violence\nstudyarea_erv <- explosion_or_remoteviolence %>% \n  filter(admin1 %in% c(\"Rakhine\", \"Chin\", \"Magway\"))\n\n# Battles\nstudyarea_bat <- battles %>% \n  filter(admin1 %in% c(\"Rakhine\", \"Chin\", \"Magway\"))\n```\n:::\n\n\n\nLet us visualise the data again.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\ntmap_style(\"white\")\n\ntm_shape(studyarea) +\n  tm_polygons() +\n  tm_shape(studyarea_vac) +\n  tm_dots(size= 0.1, col = \"black\") +\n  tm_facets(by = \"year_quarter\",\n            free.coords = FALSE,\n            drop.units = TRUE,\n            ncol = 7) +\n  tm_layout(main.title=\"Violence Against Civilians (Quarterly)\")\n\ntm_shape(studyarea) +\n  tm_polygons() +\n  tm_shape(studyarea_stdp) +\n  tm_dots(size= 0.1, col = \"black\") +\n  tm_facets(by = \"year_quarter\",\n            free.coords = FALSE,\n            drop.units = TRUE,\n            ncol = 7) +\n  tm_layout(main.title=\"Strategic Developments (Quarterly)\")\n\ntm_shape(studyarea) +\n  tm_polygons() +\n  tm_shape(studyarea_erv) +\n  tm_dots(size= 0.1, col = \"black\") +\n  tm_facets(by = \"year_quarter\",\n            free.coords = FALSE,\n            drop.units = TRUE,\n            ncol = 7) +\n  tm_layout(main.title=\"Explosion/Remote Violence (Quarterly)\")\n\ntm_shape(studyarea) +\n  tm_polygons() +\n  tm_shape(studyarea_bat) +\n  tm_dots(size= 0.1, col = \"black\") +\n  tm_facets(by = \"year_quarter\",\n            free.coords = FALSE,\n            drop.units = TRUE,\n            ncol = 7) +\n  tm_layout(main.title=\"Battles (Quarterly)\")\n```\n:::\n\n\n\n![](images/unnamed-chunk-19-1.png)\n\n![](images/unnamed-chunk-19-2.png)\n\n![](images/unnamed-chunk-19-3.png)\n\n![](images/unnamed-chunk-19-4.png)\n\n## Export and Save Data Sets (RDS file format)\n\nBefore we continue, let us export and save our data.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Study Areas\nsaveRDS(studyarea, \"data/final_rds/studyarea.rds\")\n\n# ACLED Data\nsaveRDS(studyarea_vac, \n        \"data/final_rds/studyarea_violence_against_civilians.rds\")\nsaveRDS(studyarea_stdp, \n        \"data/final_rds/studyarea_strategic_developments.rds\")\nsaveRDS(studyarea_erv, \n        \"data/final_rds/studyarea_explosion_or_remoteviolence.rds\")\nsaveRDS(studyarea_bat, \n        \"data/final_rds/studyarea_battles.rds\")\n```\n:::\n\n\n\n# Kernel Density Estimation\n\n## Import Previous Data\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstudyarea <- readRDS(\"data/final_rds/studyarea.rds\")\nstudyarea_vac <- readRDS(\"data/final_rds/studyarea_violence_against_civilians.rds\")\nstudyarea_stdp <- readRDS(\"data/final_rds/studyarea_strategic_developments.rds\")\nstudyarea_erv <- readRDS(\"data/final_rds/studyarea_explosion_or_remoteviolence.rds\")\nstudyarea_bat <- readRDS(\"data/final_rds/studyarea_battles.rds\")\n```\n:::\n\n\n\n## Separate Analysis\n\n### Create Owin Objects\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Creating the Owin objects\nChin_owin <- studyarea %>% filter(ST == \"Chin\") %>% as.owin()\nMagway_owin <- studyarea %>% filter(ST == \"Magway\") %>% as.owin()\nRakhine_owin <- studyarea %>% filter(ST == \"Rakhine\") %>% as.owin()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#| output: false\n\n# Function to split any sf object into a list of sf by year_quarter\n# Outputs a list of ppp (converted from each sf in each year_quarter)\nsplit_by_year_quarter <- function(sf_object) {\n  # Get unique year_quarter values\n  unique_quarters <- unique(sf_object$year_quarter)\n  \n  # Split the sf object into a list of sf objects by year_quarter,\n  # Then, convert to ppp objects\n  # Then, jittle the points (to handle the presence of duplicated points)\n  split_list <- lapply(unique_quarters, function(unique_quarters) {\n    sf_object %>% filter(year_quarter == unique_quarters) %>% \n      as.ppp() %>% \n      rjitter(retry=TRUE, \n              nsim=1, \n              drop=TRUE)\n  })\n  \n  # Name the list elements by their year_quarter values\n  names(split_list) <- unique_quarters\n  \n  return(split_list)\n}\n\nvac_ppp_list <- split_by_year_quarter(studyarea_vac)\nstdp_ppp_list <- split_by_year_quarter(studyarea_stdp)\nerv_ppp_list <- split_by_year_quarter(studyarea_erv)\nbat_ppp_list <- split_by_year_quarter(studyarea_bat)\n```\n:::\n\n\n\n### Separate ACLED Points by Region (using Owin)\n\nNow, let us use the Owin objects to filter the ACLED data points for each region.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Function to Extract ppp points within a specified Owin object\nfilter_ppp_within_window <- function(ppp_list, window) {\n  filtered_list <- lapply(ppp_list, function(ppp_item) {\n    ppp_item[window]\n  })\n  return(filtered_list)\n}\n\nChin_vac_ppp_list <- filter_ppp_within_window(vac_ppp_list, Chin_owin)\nChin_stdp_ppp_list <- filter_ppp_within_window(stdp_ppp_list, Chin_owin)\nChin_erv_ppp_list <- filter_ppp_within_window(erv_ppp_list, Chin_owin)\nChin_bat_ppp_list <- filter_ppp_within_window(bat_ppp_list, Chin_owin)\n\nMagway_vac_ppp_list <- filter_ppp_within_window(vac_ppp_list, Magway_owin)\nMagway_stdp_ppp_list <- filter_ppp_within_window(stdp_ppp_list, Magway_owin)\nMagway_erv_ppp_list <- filter_ppp_within_window(erv_ppp_list, Magway_owin)\nMagway_bat_ppp_list <- filter_ppp_within_window(bat_ppp_list, Magway_owin)\n\nRakhine_vac_ppp_list <- filter_ppp_within_window(vac_ppp_list, Rakhine_owin)\nRakhine_stdp_ppp_list <- filter_ppp_within_window(stdp_ppp_list, Rakhine_owin)\nRakhine_erv_ppp_list <- filter_ppp_within_window(erv_ppp_list, Rakhine_owin)\nRakhine_bat_ppp_list <- filter_ppp_within_window(bat_ppp_list, Rakhine_owin)\n```\n:::\n\n\n\n### Computing KDE (adaptive bandwidth) for each Region\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n### Separating Study Areas\n\n```{# {r}\n# # Function to filter sf object by admin1 values\n# filter_by_admin1 <- function(sf_object, regions) {\n#   filtered_list <- lapply(regions, function(region) {\n#     sf_object %>% filter(admin1 == region)\n#   })\n#   \n#   # Name the list elements by their region names\n#   names(filtered_list) <- regions\n#   \n#   return(filtered_list)\n# }\n# \n# # Define the regions to filter by\n# regions <- c(\"Chin\", \"Magway\", \"Rakhine\")\n# \n# # Each list is a list of lists of sfs for each region\n# vac_list <- filter_by_admin1(studyarea_vac, regions)\n# stdp_list <- filter_by_admin1(studyarea_stdp, regions)\n# erv_list <- filter_by_admin1(studyarea_erv, regions)\n# bat_list <- filter_by_admin1(studyarea_bat, regions)\n# \n# Chin_vac <- vac_list[[\"Chin\"]]\n# Chin_stdp <- stdp_list[[\"Chin\"]]\n# Chin_erv <- erv_list[[\"Chin\"]]\n# Chin_bat <- bat_vac_list[[\"Chin\"]]\n# \n# Magway_vac <- vac_list[[\"Magway\"]]\n# Magway_stdp <- stdp_list[[\"Magway\"]]\n# Magway_erv <- erv_list[[\"Magway\"]]\n# Magway_bat <- bat_vac_list[[\"Magway\"]]\n# \n# Rakhine_vac <- vac_list[[\"Rakhine\"]]\n# Rakhine_stdp <- stdp_list[[\"Rakhine\"]]\n# Rakhine_erv <- erv_list[[\"Rakhine\"]]\n# Rakhine_bat <- bat_vac_list[[\"Rakhine\"]]\n```",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}