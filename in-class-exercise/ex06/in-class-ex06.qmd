---
title: "06 In-class Exercise (Review)"
author: "Heng Kuan Xin"
date: 2024-09-23
date-modified: "last-modified"

toc: true
toc-expand: true
number-sections: true

execute:
  eval: true
  echo: true
  freeze: true
  output: true
  warning: false
  error: false
---

# Recap

Local Statistics -\> Test for outliers between states and its neighbours?

Tobler's First Law of Geography -\> i.e basically nearer things are more related than further things

In this lesson, we will not touch on Spatial Dependency, we will focus on Spatial Autocorrelation.

Statisticians often use it in time series data -- since time series data have a lot of cyclical or seasonal patterns.

Instead of testing for serial stability, in geospatial, we will use autocorrelation for spatial stability. Whether locations are randomly distributed or is it autocorrelated to its neighbours.

Types of Spatial Autocorrelation Interpretation:

-- Reject null hypo, can infer that there is spatial autocorrelation when interpreting, know that spatial autocorrelation is continuous, just like your correlation coefficients. e.g. in Positive Spatial Autocorrelation, we likely see a range of values from 0 to 1 (clustering is strong when nearer to 1.)

-- When you have more negative spatial autocorrelation, we are likely to see more outliers, that is the checkboard patterns.

Brief history: 1950s to 1960s --\> '[quantitative geography revolution](https://en.wikipedia.org/wiki/Quantitative_revolution)' Using quantitative methods to measure geographical phenomena.

Confidence Interval:

[![Click on Image for Reference](images/image7-8.jpg){fig-align="center" width="468"}](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2689604/)

When we reject the null hypothesis, we can only infer that spatial points are not randomly distributed, we cannot say for sure, or determine that it is really not spatially randomly distributed.

Getis-Ord Global G:

d has to be distance matrix, cannot use proximity matrix.

The function only tells us whether there are signs of positive or negative clusters –\> high-high (high value with high value neighbours) clusters and low-low (low value with low value neighbours) clusters.

Meanwhile, there are signs of outliers –\> high-low, and low-high, which means high value surrounded by low value neighbours and vice versa.

![](images/image7-15.jpg){fig-align="center" width="528"}

The function only accepts only positive variables, since we are multiplying variables together.

Local Indicator of Spatial Association (LISA)

-   Break Moran's I into local to come up with LISA
-   the LISA for each observation gives an indication of the extent of significant spatial clustering of similar values around that observation

# In-class Exercise

::: callout-note
We are going to use a different package, and therefore different method, of computing the Spatial Autocorrelation in this exercise. (Compared to Hands-on Exercise 6)
:::

In your Takehome Exercise 2, you have to use [sfdep](https://sfdep.josiahparry.com/), a wrapper of spdep, which is based on **sf** and uses tibble DataFrames, which makes working with the data a lot easier.

```{r}
pacman::p_load(sf, sfdep, tmap, tidyverse)
```

```{r}
hunan_2012 <- read_csv("data/aspatial/Hunan_2012.csv")
hunan_sf <- st_read("data/geospatial/", layer = "Hunan")

hunan_GDPPC <- left_join(hunan_sf, hunan_2012) %>% select(1:4, 7, 15)
```

Tips and Tricks:

When using mutate, include argument .before = i, to insert the new attributes before column i. This makes the tibble DataFrame easier to read when we open the table.

```{r}
wm_q <- hunan_GDPPC %>%
  mutate( nb = st_contiguity(geometry), # calculate contiguity neighbours as new column called nb
          wt = st_weights(nb,           # calculate weights as new column called wt
                          style = "W"), # row standardised weights
          .before = 1)                  # .before makes mutate insert new columns at the front!
```

## Computing Global Moran's I \[Optional\]

global_moran() function is used to compute the Moran's I value.

Different from spdep package, the output is a tibble data.frame.

```{r}
moranI <- global_moran(wm_q$GDPPC,
                       wm_q$nb,
                       wm_q$wt)
glimpse(moranI)
```

I refers to Moran's I value.

K refers to the average number of neighbours found.

## Performing Global Moran's I Test \[Base Moran I, no Simulation\]

```{r}
global_moran_test(wm_q$GDPPC,
                  wm_q$nb,
                  wm_q$wt)
```

**Check the p-value first!**

The p-value is smaller than the alpha value if confidence level = 95%. We are therefore able to reject the null hypothesis and we can say that we have enough statistical evidence such that we are 95% confident that clustering is present.

**Then interpret the Moran I statistics**

I is positive, there are signs of clustering.

## Performing Global Moran's I Permutation Test (Repeatedly Test) \[Use Simulations\]

In the real world, in fact you do not need to perform the previous tests. You can just start with the permutation test.

What if the Global Moran's I test, under randomisation,

Usually, just a hundred iterations is enough. Note that iterations start from 0. You can also use 999 if need be.

```{r}
set.seed(1234)

global_moran_perm(wm_q$GDPPC,
                  wm_q$nb,
                  wm_q$wt,
                  nsim = 99)
```

```{r}
lisa <- wm_q %>%
  mutate(local_moran = local_moran(GDPPC, 
                                   nb, 
                                   wt, 
                                   nsim = 99),
         .before = 1) %>%
  unnest(local_moran)

```

![](images/clipboard-4120759321.png){fig-align="center"}

Describing the columns:

-   **ii**: refers to your local Moran I
-   **p_ii**: p value, using base method
-   **p_ii_sim**: p value, using the simulation method –\> hundred simulations without replacement
-   **p_folded_sim**: p value, is called the pysal method, which uses K fold validation.
-   **mean**: label the clusters
    -   (if normal distribution, mean is useful)
-   **median:** label the clusters
    -   (if distribution is skewed, median is more useful) REFER TO **skewness**!

```{r}
tmap_mode("plot")
m1 <- tm_shape(lisa) +
        tm_fill( "ii")+
        tm_borders(alpha = 0.5)+ 
        tm_view(set.zoom.limits = c(6,8))+
        tm_layout(
          main.title = "Local Moran's I of GDPPC",
          main.title.size = 0.8
        )

 m2 <- tm_shape(lisa) +
          tm_fill( "p_ii",
                   breaks = c(0,0.001,0.01,0.05,1),
                   labels = c("0.001","0.01","0.05","Not significant"))+
          tm_borders(alpha = 0.5)+ 
          tm_view(set.zoom.limits = c(6,8))+
          tm_layout(
            main.title = "p-value of Local Moran I's of GDPPC",
            main.title.size = 0.8
          )
 
 tmap_arrange(m1,m2)
```

```{r}
lisa_sig <- lisa %>%
  filter(p_ii < 0.05)

tmap_mode("plot")

tm_shape(lisa) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(lisa_sig) +
  tm_fill("mean") +
  tm_borders(alpha = 0.)
```

LISA map is a categorical map showing outliers and clusters. There are two types of outliers, namely: High-Low and Low-High outliers. Likewise, there are two types of clusters namely: High_High and Low-Low clusters. In fact, LISA map is an interpreted map by combining local Moran's I of geographical areas and their respective p-values.

**Context is very important. Note that in your Take-home Exercise, you are looking at Clusters of Drug Usage.**

## Computing Local Gi\* statistics

As usual, we will need to derive a spatial weight matrix before we can compute local Gi\* statistics, Code chunk below will be used to derive a spatial weight matrix by using sfdep functions and tidyverse approach.

You will also need to include

```{r}
wm_idw <- hunan_GDPPC %>%
  mutate( nb = st_contiguity(geometry),
          wt = st_inverse_distance(nb, geometry,
                                   scale = 1,
                                   alpha = 1),
          .before = 1)
```

```{r}
HCSA <- wm_idw %>%
  mutate( local_Gi = local_gstar_perm(GDPPC, nb, wt, nsim = 99),
          .before = 1) %>%
  unnest(local_Gi)

HCSA
```
