---
title: "Preliminary Analysis (EDA) for Housing Price in Johor Bahru"
subtitle: "Geospatial Analytics"
author: "Heng Kuan Xin"
date: "2024-10-31"
date-modified: "last-modified"

execute: 
  eval: true
  echo: true
  freeze: true
---

```{r}
pacman::p_load(sf, tmap, tidyverse, tidygeocoder, matrixStats, units)
```

# Reading the Data

## Study Area (Admin Boundary Level 3)

```{r}
study_area <- st_read(dsn = "data/geospatial/admin_boundaries", 
                      layer = "geoBoundaries-MYS-ADM3") %>%
  filter(shapeName %in% c(
    "BANDAR JOHOR BAHRU", "MUKIM PLENTONG", "MUKIM PULAI",
    "MUKIM TEBRAU", "MUKIM BUKIT BATU", "MUKIM KULAI",
    "MUKIM SEDENAK", "MUKIM SENAI", "MUKIM JELUTONG",
    "MUKIM TANJUNG KUPANG", "BANDAR KULAI"
  )) %>% select(c(1,5,6)) %>% 
    st_set_crs(4326) %>%  # Set the CRS to WGS84
    st_transform(3377) %>% # Transform to Johor Bahru's appropriate CRS
    st_zm()
```

### Extract Study Area

After importing, I realise that several polygons are not located within the the supposedly Johor Bahru District, so we will split the polygons, and clean up wanted polygons.

```{r}
# Split into individual polygons
study_area_split <- study_area %>%
  filter(shapeName %in% c("MUKIM PULAI", "MUKIM JELUTONG")) %>%
  st_cast("POLYGON")

# Convert row names (fractional indices) to a new column for polygon IDs
study_area_split <- study_area_split %>%
  mutate(polygon_id = row.names(study_area_split))

# Plot using tmap to visualize each polygon with its unique fractional index ID
tmap_mode("plot")
tm_shape(study_area_split) +
  tm_polygons("polygon_id") +
  tm_text("polygon_id", size = 0.7, col = "black")
```

The map above shows multiple polygons outside of Johor Bahru, our study area. We will therefore identify the respective polygon.ids of polygons outside of our study area and remove them from our data set.

```{r}
# Cleaning up unwanted data
study_area_split <- study_area_split %>% 
  # Remove unwanted polygons
  filter(polygon_id %in% c(1,2)) %>% # polygon_id with values 1 or 2
  # Remove the polygon_id column
  select(-c("polygon_id"))

# Remove the row names
rownames(study_area_split) <- NULL

# Combine the modified areas back with the rest of the study area
study_area_cleaned <- study_area %>%
  filter(!shapeName %in% c("MUKIM PULAI", "MUKIM JELUTONG")) %>%
  bind_rows(study_area_split)
```

After extracting the cleaned study area, we will export it to a file for future uses.

```{r}
write_rds(study_area_cleaned, "data/rds/study_area.rds")
```

Clear our temporary variables in our environment

```{r}
rm(study_area, study_area_cleaned, study_area_split)
```

Read back the exported file (for future runs).

```{r}
study_area <- read_rds("data/rds/study_area.rds")
```

## Property Sales Data

```{r}
property_data <- read_delim(
  "data/aspatial/Open Transaction Data.csv", 
  delim = "\t", 
  locale = locale(encoding = "UTF-16") # Specify encoding
) %>% select(-c(9,11,12,14))
```

```{r}
colnames(property_data)
```

```{r}
# Relabelling Data Columns
property_data <- property_data %>%
  # Step 1: Drop all rows with empty values
  drop_na() %>%
  # Step 2: Clean up Column Name Error
  rename(
    `Transaction Price` = `Transaction Price  `,
  ) %>%
  # Step 3: Convert 'Transaction Price' from string to numeric
  mutate(
    `Transaction Price` = `Transaction Price` %>%
      gsub(pattern = "RM", replacement = "") %>%   # Remove 'RM'
      gsub(pattern = ",", replacement = "") %>%     # Remove commas
      as.numeric()                                  # Convert to numeric
  ) %>%
  # Step 4: Convert Main Floor Area from string to numeric
  mutate(
    `Main Floor Area` = `Main Floor Area` %>% as.numeric()
  ) %>%
  # Step 5: Replace abbreviations and trim whitespace
  mutate(
    `Road Name` = str_replace_all(`Road Name`, "\\bJLN\\b", "Jalan"),
    `Road Name` = str_replace_all(`Road Name`, "\\bTMN\\b", "Taman"),
    `Scheme Name/Area` = str_replace_all(`Scheme Name/Area`, "\\bJLN\\b", "Jalan"),
    `Scheme Name/Area` = str_replace_all(`Scheme Name/Area`, "\\bTMN\\b", "Taman")
  ) %>%
  # Step 6: Trim whitespace from the specified columns
  mutate(
    `Road Name` = str_trim(`Road Name`),
    `Scheme Name/Area` = str_trim(`Scheme Name/Area`),
    `Mukim` = str_trim(`Mukim`),
    `District` = str_trim(`District`)
  ) %>%
  # Step 7: Select only 2023 Data Set
  filter(grepl("2023", `Month, Year of Transaction Date`)) %>%
  # Step 8: Calculate Price per Area
  mutate(
    `Price Per Floor Area` = 
      (`Transaction Price` / `Main Floor Area`) %>% round(.,digits=2)
  ) %>%
  # Step 9: Create the address column
  mutate(
    address = paste0(`Road Name`, ', ', `Scheme Name/Area`, ', ', `Mukim`, ', ', `District`)
  ) %>%
  # Step 10: Clean up the column names
  rename(
    `Transaction Price (RM)` = `Transaction Price`,
    `Land/Parcel Area (SqM)` = `Land/Parcel Area`,
    `Main Floor Area (SqM)` = `Main Floor Area`
  ) %>%
  # Step 11: Ensure no null values during calculation and data type conversion
  drop_na()
```

```{r}
#| eval: false
random_sample <- sample_n(property_data, 100)
property_data_geocoded <- geocode_batch(random_sample)
```

```{r}
# # Function to geocode in batches with delays to avoid being blocked
# geocode_batch <- function(data, batch_size = 500) {
#   results <- data.frame()
#   for (i in seq(1, nrow(data), by = batch_size)) {
#     batch <- data[i:min(i + batch_size - 1, nrow(data)), ]
#     batch <- batch %>%
#       geocode(
#       address = `address`,               # Column containing the address
#       method = 'google',                 # Use Google Geocoding API
#       api_key = google_api_key,          # Provide your API key
#       full_results = TRUE                # Get full results (optional)
#     )
#     results <- bind_rows(results, batch)
#     Sys.sleep(60) # wait 60 seconds between batches to avoid rate limits
#   }
#   return(results)
# }
```

```{r}
property_data <- read_rds("data/rds/property_preprocessed.rds") %>% 
    st_set_crs(4326) %>%  # Set the CRS to WGS84
    st_transform(3377) %>% # Transform to Johor Bahru's appropriate CRS
    st_zm()
```

## Amenities Data (OpenStreetMap(OSM))

```{r}
# Set the directory for the files
file_dir <- "data/geospatial/osm_extract2_combined/"

# List of amenities files to read
files <- c(
  "border(border_control_facilities).geojson",
  "border(coastlines).geojson",
  "border(waterfronts_and_beaches).geojson",
  "education(kindergartens).geojson",
  "education(schools).geojson",
  "education(universities_and_colleges).geojson",
  "government_office(offices,townhalls).geojson",
  "government_office(police_and_fire_stations).geojson",
  "healthcare(hospitals_and_specialists).geojson",
  "landuse(cemetery).geojson",
  "landuse(commercial).geojson",
  "landuse(industrial).geojson",
  "recreation(parks_and_green_spaces).geojson",
  "recreation(theme_parks_and_resorts).geojson",
  "religion(buddhist_temples).geojson",
  "religion(churches).geojson",
  "religion(hindu_temples).geojson",
  "religion(mosques).geojson",
  # "religion(place_of_worship).geojson",
  "retail_and_commercial(marketplace,malls).geojson",
  "retail_and_commercial(restaurant, cafe, fast_food).geojson",
  "retail_and_commercial(supermarket,convenience).geojson",
  "transportation(airport).geojson",
  "transportation(bus_stops).geojson",
  "transportation(bus_terminals).geojson",
  "transportation(carparks).geojson",
  "transportation(petrol_stations).geojson"
)

# Read all files using lapply and store them in a list
amenities <- lapply(files, function(file) {
  st_read(dsn = paste0(file_dir, file)) %>%
    st_set_crs(4326) %>%  # Set the CRS to WGS84
    st_transform(3377) %>% # Transform to Johor Bahru's appropriate CRS
    st_zm() %>%            # Eliminate the z dimension
    select(name, geometry) # Select relevant columns
})

# Set names based on the amenity extracted from the file names
names(amenities) <- gsub(".*\\((.*)\\).*", "\\1", files)
```

## Data Cleaning

```{r}
tmap_mode("view")
tm_shape(amenities$`border_control_facilities`) +
  tm_dots()
```

```{r}
# Filter the customs_facilities data and replace the entry in amenity_data
amenities[["border_control_facilities"]] <- amenities[["border_control_facilities"]] %>%
  filter(
    str_detect(str_to_lower(name), str_to_lower("Sultan Abu Bakar")) |
    str_detect(str_to_lower(name), str_to_lower("Johor Bahru"))
  )

# Rename to amenity type to customs
names(amenities)[names(amenities) == "border_control_facilities"] <- "customs_facilities"
```

```{r}
proximity <- function(df1, df2, varname) {
  dist_matrix <- st_distance(df1, df2) %>%
    drop_units()
  df1[,varname] <- rowMins(dist_matrix)
  return(df1)
}
```

```{r}
# Calculate proximity for each amenity and add to property_data
for (amenity in names(amenities)) {
  
  property_data <- proximity(property_data, amenities[[amenity]], 
                             paste0("PROX_", toupper(amenity)))
}
```

```{r}
write_rds(property_data, "data/rds/proximity_matrix.rds")
```

```{r}
property_sales <- read_rds("data/rds/proximity_matrix.rds")

tmap_mode("plot")

tm_shape(study_area) + tm_fill() + tm_borders(alpha=0.2) +
  tm_shape(property_sales) + tm_dots("PROX_HOSPITALS_AND_SPECIALISTS", 
                                    breaks = c(0, 500, 1000, 2000, 5000, Inf),
                                    palette="-viridis")
                            

```
